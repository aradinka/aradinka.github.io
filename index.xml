<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Aradinka | Digital Garden on</title><link>https://aradinka.github.io/</link><description>Recent content in Aradinka | Digital Garden on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://aradinka.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://aradinka.github.io/tags/authors-ali-abdaal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/tags/authors-ali-abdaal/</guid><description/></item><item><title/><link>https://aradinka.github.io/Untitled/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/Untitled/</guid><description/></item><item><title>7 Myths Ruining Your Sleep</title><link>https://aradinka.github.io/7-myths-ruining-your-sleep/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/7-myths-ruining-your-sleep/</guid><description>It doesn&amp;rsquo;t matter when you sleep, as long as you sleep enough Everyone needs 8 hours of sleep We should wake up at the same time every day Avoid blue light before sleep Sleep apps help you sleep better Melatonin helps us sleep better Polyphasic sleep is good for your productivity Source: [[ali-abdaal]] video, Why You&amp;rsquo;re Always Tired - 7 Myths Ruining Your Sleep</description></item><item><title>_areas</title><link>https://aradinka.github.io/_areas/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/_areas/</guid><description>Productivity</description></item><item><title>_authors</title><link>https://aradinka.github.io/_authors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/_authors/</guid><description>Ali Abdaal</description></item><item><title>ab-testing</title><link>https://aradinka.github.io/ab-testing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ab-testing/</guid><description>Overview A/B testing is a popular way to test your products. A/B testing is one of the most prominent and widely used statistical tools.</description></item><item><title>activation function</title><link>https://aradinka.github.io/activation-function/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/activation-function/</guid><description>Activation function are important for an ANN to learn and make sense of something complicated like non-linear complex functional mappings between the inputs and response variable.</description></item><item><title>ali-abdaal</title><link>https://aradinka.github.io/ali-abdaal/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ali-abdaal/</guid><description/></item><item><title>analysis-step</title><link>https://aradinka.github.io/analysis-step/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/analysis-step/</guid><description> check .columns .describe() data check missing values check mean &amp;amp; [[standard-deviation]] values check min, percentil, max valeus</description></item><item><title>back propagation</title><link>https://aradinka.github.io/back-propagation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/back-propagation/</guid><description>Backpropagation:
Is a short form of &amp;ldquo;backward propagation of errors&amp;rdquo; It&amp;rsquo;s the standard method of training [[artificial-neural-network]] It helps to calculate the [[gradient]] of a [[loss-function]] with respects to all the weights in the network This method of fine-tuning the weights of a neural net based on the errors rate obtained in the previous epoch.</description></item><item><title>batch-size</title><link>https://aradinka.github.io/batch-size/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/batch-size/</guid><description>Baca tentang [[batch-nomalization]]
Batch size salah satu yang bisa kita tuning. Tuning batch sizenya sampai kita mendapatkan performa yang maksimum</description></item><item><title>bias</title><link>https://aradinka.github.io/bias/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/bias/</guid><description>Bias is a learner’s tendency to consistently learn the same wrong thing
Bias is the difference between the expected average prediction of the model, and the correct pvalue which we are trying to predict.</description></item><item><title>bias-vs-variance</title><link>https://aradinka.github.io/bias-vs-variance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/bias-vs-variance/</guid><description>It provides another perspective to look at the phenomenon of [[underfitting]] and [[overfitting]]
[[bias]] is a learner’s tendency to consistently learn the same wrong thing</description></item><item><title>cheat-sheet</title><link>https://aradinka.github.io/cheat-sheet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/cheat-sheet/</guid><description>ML Algorithm Datacamp https://www.datacamp.com/cheat-sheet/machine-learning-cheat-sheet
Microsoft Azure https://learn.microsoft.com/en-us/azure/machine-learning/algorithm-cheat-sheet</description></item><item><title>chronotype</title><link>https://aradinka.github.io/chronotype/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/chronotype/</guid><description>Morning [[chronotype]]: People that prefer to wake up early and sleep early. Focusses better in the morning
Evening [[chronotype]]: People that prefer to wake up late and sleep late.</description></item><item><title>circadian-rhythms</title><link>https://aradinka.github.io/circadian-rhythms/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/circadian-rhythms/</guid><description>It&amp;rsquo;s your body internal clock
It&amp;rsquo;s signal to your body what you need at a given time</description></item><item><title>classification</title><link>https://aradinka.github.io/classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/classification/</guid><description>Why we can’t do a classification problem using Regression? With linear regression you fit a polynomial through the data - say, like on the example below, we fit a straight line through {tumor size, tumor type} sample set:</description></item><item><title>code-screen</title><link>https://aradinka.github.io/code-screen/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/code-screen/</guid><description>outside session 1 2 3 4 5 6 7 8 # create screen session screen -S session_name # kill complete session screen -S [session_name] -X quit # detatch running session screen -d [session_name}] inside session 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # create new window ctrl a, c # list all window ctrl a, &amp;#34; # split horizontally ctrl a, s # change between tab ctrl a, tab # exit window ctrl a, d</description></item><item><title>code-sklearn</title><link>https://aradinka.github.io/code-sklearn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/code-sklearn/</guid><description>1 2 3 4 5 6 from sklearn.tree import DecisionTreeRegressor from sklearn.ensemble import RandomForestRegressor from sklearn.model_selection import train_test_split from sklearn.</description></item><item><title>code-sql</title><link>https://aradinka.github.io/code-sql/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/code-sql/</guid><description>SQL is the programming language used with databases
Summary 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 -- functions REPEAT(&amp;#39;@&amp;#39;,10)UPPER()LOWER()CURDATE()DAY(CURDATE())NOW()LENGHT(&amp;#39;str&amp;#39;)CHARACTER_LENGHT(&amp;#39;str&amp;#39;)CHAR_LENGHT(&amp;#39;str&amp;#39;)CONCAT(&amp;#39;Hello &amp;#39;.</description></item><item><title>confusion-matrix</title><link>https://aradinka.github.io/confusion-matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/confusion-matrix/</guid><description>Summary A good model has high TP and TN, while low FP(error 1 $\alpha$) and FN(error 2 $\theta$). Or F1 score has high value</description></item><item><title>conversion-rate</title><link>https://aradinka.github.io/conversion-rate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/conversion-rate/</guid><description>What is conversion rate? Conversion rate is often used by e-commerce sites to measure the percentage of visitors that end up purchasing products.</description></item><item><title>convolutional-neural-network</title><link>https://aradinka.github.io/convolutional-neural-network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/convolutional-neural-network/</guid><description>Kenapa cnn bagus untuk dipakai di data image, text, audio dan video?
Mencerminkan spatial correlation between features Di data image: Pixel di titik i, j sangat berkaitan dengan i+1, j+1.</description></item><item><title>credit scoring</title><link>https://aradinka.github.io/credit-scoring/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/credit-scoring/</guid><description>Apakah nasabah layak diberikan pinjaman?
Data: Profil nasabah
Problem dari nasabah: Proses yang perlu dilalui butuh waktu lama
Data kaggle Credit Card Approval Prediction</description></item><item><title>data-engineer-roadmap</title><link>https://aradinka.github.io/data-engineer-roadmap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/data-engineer-roadmap/</guid><description>CS Fundamentals:
Basic terminal usage [[data-structure-and-algorithm]] [[api]] [[rest-api]] linux [[cli]] [[vim-bindings]] [[shell-scripting]] [[cronjobs]] how does computer work?</description></item><item><title>data-science</title><link>https://aradinka.github.io/data-science/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/data-science/</guid><description>Data Science Across Industries ![[images/Data Science Across Industries.png]]</description></item><item><title>decision-tree</title><link>https://aradinka.github.io/decision-tree/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/decision-tree/</guid><description>Summary It&amp;rsquo;s a tree-shaped supervised learning algorithm, works on if-then statement, that can be used in classification and regression problems. The input can be both continuous and categorical.</description></item><item><title>difference-between-logistic-and-linear-regression</title><link>https://aradinka.github.io/difference-between-logistic-and-linear-regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/difference-between-logistic-and-linear-regression/</guid><description>Linear and Logistic regression are the most basic form of regression which are commonly used.
Linear Logistic dependent variable is continuous dependent variable is binary requires to establish the linear relationship among dependent and independent variables not necessary for logistic regression independent variable can be correlated with each other the variable must not be correlated with each other</description></item><item><title>ds</title><link>https://aradinka.github.io/ds/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ds/</guid><description/></item><item><title>ds cover letter</title><link>https://aradinka.github.io/ds-cover-letter/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ds-cover-letter/</guid><description>Dear hiring manager,
I would like to introduce myself as an applicant for Data Scientist position at your company. I am confident in my ability to perform data science related task due to my internship experience and my education background.</description></item><item><title>ds-fmcg</title><link>https://aradinka.github.io/ds-fmcg/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ds-fmcg/</guid><description>Goals Managing the inventory is crucial for the revenue stream Meeting the demand is important to not lose potential revenue Stocking excessive products could lead to losses ML Case Study Example Predict the sales of products across stores for one month</description></item><item><title>ds-hack</title><link>https://aradinka.github.io/ds-hack/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ds-hack/</guid><description> save tabular files to parquet format youtube change string column to category downcasting integers int8 range : -128 to 127 int16 range: -32678 to 32676 downcasting float to float32 (check some values behind decimals) change yes no column to boolean speed up pandas df looping -&amp;gt; apply() -&amp;gt; vectorized</description></item><item><title>ds-interview</title><link>https://aradinka.github.io/ds-interview/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ds-interview/</guid><description>Tell me about yourself! Nama saya Azka, saat ini saya berdomisili di Kota Bogor. Saya merupakan fresh graduates jurusan statistika dari Institut Teknologi Sepuluh Nopember.</description></item><item><title>ds-ml-step</title><link>https://aradinka.github.io/ds-ml-step/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ds-ml-step/</guid><description>ML steps:
determine which type of ML problems we would like to solve gather data [[feature-engineering]] Reference</description></item><item><title>ds-plotting</title><link>https://aradinka.github.io/ds-plotting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ds-plotting/</guid><description>Read csv parse_dates index_col Plotting in notebook setup 1 2 3 4 5 import pandas as pd pd.</description></item><item><title>ds-skill</title><link>https://aradinka.github.io/ds-skill/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ds-skill/</guid><description> read datas check dtypes (handling datetime data, index_col) check memory usage summary data summary distribution summary between some categorical variable [[feature-engineering]] [[detect-extreme-values]] [[handling-missing-values]] take out variable complete case (buang baris yang memiliki missingg value) [[cross-validation]] [[hyper-parameter-tuning]] modelling evaluasi model metrics [[confusion-matrix]]</description></item><item><title>entropy</title><link>https://aradinka.github.io/entropy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/entropy/</guid><description>In statistics, entropy is a measure of information
varies from 0 to 1 0: all the data belong to a single class 1: the class distribution is equal a measure of the amount of uncertainity in the data set when $H(S)=0$, the set is perfectly classified (all element in $S$ are of the same class) Let’s assume that a dataset T associated with a node contains examples from n classes.</description></item><item><title>excel-cheatsheet</title><link>https://aradinka.github.io/excel-cheatsheet/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/excel-cheatsheet/</guid><description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 SUM() AVERAGE() IF() COUNT() COUNTA() MAX() MIN() SUMIF() COUNTIF() TRIM() LOWER() UPPER() PROPER() CONCATENTATE() LEN() LEFT() MID() RIGHT() ROUNDUP() ROUNDDOWN() ROUND() CEILING() FLOOR() MROUND() VLOOKUP() HLOOKUP() IFERROR()</description></item><item><title>export-android-lib</title><link>https://aradinka.github.io/export-android-lib/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/export-android-lib/</guid><description>Default Default AndroidManifest.xml
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 &amp;lt;?</description></item><item><title>feature-engineering</title><link>https://aradinka.github.io/feature-engineering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/feature-engineering/</guid><description>a group of activities that trasnform data into desired format
example:
splitting data into training and testing handle missing values encode categorical attributes the outermost interface that we interact with the model</description></item><item><title>fitting</title><link>https://aradinka.github.io/fitting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/fitting/</guid><description> The step of capturing patterns from data is called fitting</description></item><item><title>gaussian distribution</title><link>https://aradinka.github.io/gaussian-distribution/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/gaussian-distribution/</guid><description/></item><item><title>General Architechture of Machine Learning</title><link>https://aradinka.github.io/general-architechture-of-machine-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/general-architechture-of-machine-learning/</guid><description>Business Understanding: Understand the give use case and also it&amp;rsquo;s good to know more about the domain for which the use cases are built.</description></item><item><title>gini-impurity-index</title><link>https://aradinka.github.io/gini-impurity-index/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/gini-impurity-index/</guid><description>Gini Index is related to the misclassification probability of a random sample
Gini Index may result in values inside the interval [0, 0.</description></item><item><title>gradient descent</title><link>https://aradinka.github.io/gradient-decent/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/gradient-decent/</guid><description>It&amp;rsquo;s an iterative ML optimization algorithm It reduce the cost function It help models to make accurate predictions Gradient indicates the direction of increase</description></item><item><title>great-videos</title><link>https://aradinka.github.io/great-videos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/great-videos/</guid><description>inside-ali-abdaal-second-brain</description></item><item><title>health-innovation-sprint-accelerator</title><link>https://aradinka.github.io/health-innovation-sprint-accelerator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/health-innovation-sprint-accelerator/</guid><description>Juara 2022 105 peserta, 15 tim terpilih
Nalagenetics (Clinical Decision Support) Bio-tech Perangkat lunak yang terdiri atas beberapa modul Menjaga kualitas pengembangan produk keamanan dan kerahasiaan data Menggunakan standard ISO Modul pre-test analisis raw data menjadi VCF file reporting laporan klinis dashboard untuk melihat varian yang telah ditest dan hasil prediksi resiko Femicam (FEMICAM Medical Camera) Health-tech Kamera medis yang memeriksa leher rahim untuk membantu mendeteksi dini kanker rahim Semudah Health (NIRGOMO) Health-tech Alat pemantauan glukosa mandiri noninvansif dengan teknologi near-infrared soectroscopy untuk mengukur konsentrasi gula darah dalam bentuk sinyal Photoplethysmography BIGStar (Big Data in Support of Analyctical Research) Health-tech Aplikasi web based Menghimpun data rekam medis pasien yang diolah ke dalam variabel penelitian Sudah digunakan dalam ruang lingkup RSUP Dr.</description></item><item><title>hyper-parameter-tuning</title><link>https://aradinka.github.io/hyper-parameter-tuning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/hyper-parameter-tuning/</guid><description>The reason that it is highlighted as &amp;lsquo;hyper&amp;rsquo; is because the parameters that we tune are the outermost interface that we interact with the model, which would eventually have impacts on the underlying parameters of the model</description></item><item><title>hypothesis</title><link>https://aradinka.github.io/hypothesis-testing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/hypothesis-testing/</guid><description>What is hypothesis? A hypothesis is a concept that is not yet verified, but if true would explain certain facts or phenomena</description></item><item><title>impurity</title><link>https://aradinka.github.io/impurity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/impurity/</guid><description>impurity is a measure of homogeneity of the labels at the node at hand
Define impurity:
There are different ways to define impurity.</description></item><item><title>inside-ali-abdaal-second-brain</title><link>https://aradinka.github.io/inside-ali-abdaal-second-brain/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/inside-ali-abdaal-second-brain/</guid><description>https://youtu.be/-Y_6U0FoqDk</description></item><item><title>lean-java</title><link>https://aradinka.github.io/lean-java/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/lean-java/</guid><description>we can&amp;rsquo;t redeclare variables multiple times in the same code blocks static method can only work with static variables dtypes primitive dtypes: int, double, float, boolean</description></item><item><title>logistic-regression</title><link>https://aradinka.github.io/logistic-regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/logistic-regression/</guid><description>The logistic regression technique involves the dependent variable, which can be represented in the binary (0 or 1, true or false, yes or no) values, which means that the outcome could only be in either one form of two.</description></item><item><title>loss-function</title><link>https://aradinka.github.io/loss-function/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/loss-function/</guid><description>the cost that is incurred by the difference between the prediction and the true value. The larger the difference, the bigger the loss.</description></item><item><title>machine-learning-algorithm</title><link>https://aradinka.github.io/machine-learning-algorithm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/machine-learning-algorithm/</guid><description>A machine learning algorithm is the process that uncovers the underlying relationship whith the data
The outcome of a machine learning algorithm is called [[machine-learning-model]], which can be considered as a function $F$, which outputs certain results, when given the input.</description></item><item><title>machine-learning-model</title><link>https://aradinka.github.io/machine-learning-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/machine-learning-model/</guid><description>Rather than a predifined and fixed function, a machine learning model is dedrived from historical data. Therefore, when fed with with different data, the output of [[machine-learning-algorithm]] changes, i.</description></item><item><title>main-prediction</title><link>https://aradinka.github.io/main-prediction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/main-prediction/</guid><description>a learner is playing a dart-throwing game
how many points that the player would score?
https://leetcode.</description></item><item><title>mean-absolute-error</title><link>https://aradinka.github.io/mean-absolute-error/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/mean-absolute-error/</guid><description>Interpretation On average, our predictions are off by about X</description></item><item><title>ml-kit-vision</title><link>https://aradinka.github.io/ml-kit-vision/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ml-kit-vision/</guid><description>Text Recognition MainActivity.java
onCreate() runTextRecognition() onSuccess() processTextRecognitionResult() runFaceContourDetection() onSuccess() processFaceContourDetectionResult() onFailure() showToast() getImageMaxWidth() getImgeMaxHeight() getTargetedWidthHeight() onItemSelected() onNothingSelected() getBitmapFromAsset()</description></item><item><title>openai function calling</title><link>https://aradinka.github.io/openai-function/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/openai-function/</guid><description>Kita bisa mendeskripsikan sebuah function dalam prompt, model akan secara cerdas membuat output berupa JSON yang berisi argument-argument yang dibutuhkan oleh function yang dibentuk</description></item><item><title>optical-character-recognition</title><link>https://aradinka.github.io/optical-character-recognition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/optical-character-recognition/</guid><description>Computer Vision Research Papers Popularity Image classification: 2881 papers with code Object detection: 2671 papers with code Semantic segmentation: 3562 papers with code Face recognition: 450 papers with code Optical character recognition: 216 papers with code Anatomi OCR Text Detection model Text Recognition model Key Information Extraction Mendapatkan Model Using pre-trained model only</description></item><item><title>optimizers</title><link>https://aradinka.github.io/optimizers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/optimizers/</guid><description/></item><item><title>overfitting</title><link>https://aradinka.github.io/overfitting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/overfitting/</guid><description>An overfitting model is the one that fits well with the training data, i.e. little or no error, however it does not generalized well to the unseen data</description></item><item><title>p-value</title><link>https://aradinka.github.io/p-value/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/p-value/</guid><description>What is p-value?
p-value is a statistical measurement used to validate a hypothesis againts observed data What does the p-value measures?</description></item><item><title>pacmann</title><link>https://aradinka.github.io/pacmann/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/pacmann/</guid><description>[[pacmann-intro-to-ml]]
Notes:
Mengaplikasikan SOTA bukan tujuan DS Sanity check! file ipynb dari atas sampe bawah harus bisa sekali run Todo:</description></item><item><title>pacmann-intro-to-ml</title><link>https://aradinka.github.io/pacmann-intro-to-ml/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/pacmann-intro-to-ml/</guid><description>Pemateri: Rezka https://rezkaaufar.github.io/
Kelas 1 - 14 Feb 2022
Menemukan fungsi (approximation functions/model) dari fenomena yang terjadi di dunia nyata Traditional programming vs machine learning Tidak ada Bagaimana strategi membangun credit scoring pada perusahaan yang belum mempunyai data historis</description></item><item><title>positioning</title><link>https://aradinka.github.io/positioning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/positioning/</guid><description>Positioning helps you understand how to talk about your product / service, in order to maximize customer lifetime value
What type of brand message will increase and ensure brand trust?</description></item><item><title>probability-and-statistically-significance-explained</title><link>https://aradinka.github.io/probability-and-statistically-significance-explained/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/probability-and-statistically-significance-explained/</guid><description>Significance level (alpha) Denoted as alpha or $\alpha$ The probability of rejecting the null hypothesis when it is true Generally, we use the significance value of 0.</description></item><item><title>project-audio-conversation-transcription</title><link>https://aradinka.github.io/project-audio-conversation-transcription/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/project-audio-conversation-transcription/</guid><description>Details Packages:
TensorFlow: Model SoundFile: Pydub webrtcvad pyannote.audio scikit-learn: hierarchical, spectral, silhouette_score scipy: read and write audio files, create laplacian matrix spectral clustering Questions Bagaimana model deep learningnya?</description></item><item><title>project-madani</title><link>https://aradinka.github.io/project-madani/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/project-madani/</guid><description/></item><item><title>prompt engineering</title><link>https://aradinka.github.io/prompt-engineering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/prompt-engineering/</guid><description>Five Principles of Prompting What is prompt engineering? It&amp;rsquo;s getting increasingly impossible to keep up with AI:
published papers on arXiv growing exponentially open source AI projects (stable diffusion, AgentGPT) are the fastest growing projects on GitHub Midjourney discord server has 15M members It is becoming increasingly challenging to stay updated with the rapid advancements in the field of artificial intelligence (AI).</description></item><item><title>random-forest</title><link>https://aradinka.github.io/random-forest/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/random-forest/</guid><description>Advantages &amp;amp; Disadvantages Advantages Reduces [[overfitting]] Higher accuracy compared to other models The rationale is that an ensemble of models is likely more accurate than a single tree.</description></item><item><title>random-sampling</title><link>https://aradinka.github.io/random-sampling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/random-sampling/</guid><description>It&amp;rsquo;s a technique where each sample in a population has an equal change of being chosen
It eliminates sampling bias -&amp;gt; We want our sample to be representative of the entire population rather the sample itself</description></item><item><title>random-state</title><link>https://aradinka.github.io/random-state/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/random-state/</guid><description>Many machine learning models allow some randomness in model training. Specifying a number for random_state ensures you get the same results in each run.</description></item><item><title>regularization</title><link>https://aradinka.github.io/regularization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/regularization/</guid><description>penalizing the model that is over-complicated so that the algorithm is steered to generate a less complicated model while fitting the data</description></item><item><title>rfm-analysis</title><link>https://aradinka.github.io/rfm-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/rfm-analysis/</guid><description>What is RFM? Are all my customers similar?
What differentiated them from each other?
Who is the most likely customer?</description></item><item><title>semi-supervised-learning</title><link>https://aradinka.github.io/semi-supervised-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/semi-supervised-learning/</guid><description>The data set is massive but the labeled sample are few
Training strategy:
we train a model with the labeled data, then we apply the model to predict the unlabeled data first cluster the images into groups (unsupervised learning), and then apply the supervised learning algorithm on each of the groups individually Reference</description></item><item><title>sigmoid</title><link>https://aradinka.github.io/sigmoid/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/sigmoid/</guid><description>f(x) = 1 / (1+exp(-x))
It&amp;rsquo;s range between 0 and 1</description></item><item><title>standard-deviation</title><link>https://aradinka.github.io/standard-deviation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/standard-deviation/</guid><description> standard deviation measures how numerically spread out the values are</description></item><item><title>stochastic gradient descent</title><link>https://aradinka.github.io/stochastic-gradient-descent/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/stochastic-gradient-descent/</guid><description>Algorithm:
Shuffle the datasets -&amp;gt; so that we get a randomised dataset</description></item><item><title>subscription</title><link>https://aradinka.github.io/subscription/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/subscription/</guid><description> rize: $9 obsidian publish: 8$ chatgpt: 7$ framer: 5$ apple music: 1$</description></item><item><title>supervised-learning</title><link>https://aradinka.github.io/supervised-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/supervised-learning/</guid><description>An important measurement for supervised learning algorithms, is the generalization, which measures how well that a model derived from the training data can predict the desired attribute of the unseen data.</description></item><item><title>t-test</title><link>https://aradinka.github.io/t-test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/t-test/</guid><description>Two-sample T-test Most commonly used hypothesis test. It is applied to compare whether the average difference between the two groups</description></item><item><title>Tags System</title><link>https://aradinka.github.io/tags-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/tags-system/</guid><description>PARA Methods P.A.R.A. stands for Projects — Areas — Resources — Archives, the four top-level categories that encompass every type of information you might encounter in your work and life.</description></item><item><title>tags-list</title><link>https://aradinka.github.io/tags-list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/tags-list/</guid><description> all-post algorithm what-is</description></item><item><title>tanh</title><link>https://aradinka.github.io/tanh/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/tanh/</guid><description>Tanh also called a hyperbolic tangent function</description></item><item><title>targeting</title><link>https://aradinka.github.io/targeting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/targeting/</guid><description>Targteting involves:
understanding the routines and customer behavior of these segments, allowing you to consider and choose the ideal way to speak to them Where do my customer interact with the brand?</description></item><item><title>techinasia lead in ai era</title><link>https://aradinka.github.io/techinasia-lead-in-ai-era/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/techinasia-lead-in-ai-era/</guid><description>Sinarmas Land bikin product OneSmile: Aplikasi smart city punya bintaro
GitHib Labs &amp;amp; GitHub Chat VSCode extension: Masih perlu waiting list</description></item><item><title>temp-notes</title><link>https://aradinka.github.io/temp-notes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/temp-notes/</guid><description>Update:
district &amp;amp; subdistrict Blocker: Todo:
OpenAI function call 500(course pacmann) + 1.8 saham jul mar 1.</description></item><item><title>time series</title><link>https://aradinka.github.io/time-series/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/time-series/</guid><description>Test</description></item><item><title>uji-rata-rata-1-populasi</title><link>https://aradinka.github.io/uji-rata-rata-1-populasi/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/uji-rata-rata-1-populasi/</guid><description>Bagaimana melakukan Uji Rata-rata 1 Populasi dengan nilai varians diketahui?
Diasumsikan bahwa $X \sim N(\mu, \sigma^2) ; \sigma^2&amp;gt;0$ Hipotesis uji satu arah $H_0:\mu=\mu_0$ $H_1:\mu&amp;gt;\mu_0$ atau $H_1:\mu&amp;lt;\mu_0$ (uji sisi kanan dan sisi kiri) Hipotesis uji dua arah $H_0:\mu=\mu_0$ $H_1:\mu \neq \mu_0$ Statistik uji $Z_{hit} = \frac{\bar X - \mu_0}{\sigma / \sqrt{n}}$ Daerah kritis / penolakan $H_0$ uji satu arah Tolak $H_0$ jika $Z_{hit} &amp;gt; Z_{\alpha}$ (sisi kanan) Tolak $H_0$ jika $Z_{hit} &amp;lt; -Z_{\alpha}$ (sisi kiri) Daerah kritis / penolakan H_0 uji dua arah Tolak $Z_{hit} &amp;gt; Z_{\alpha/2}$ jika $Z_{hit}$ &amp;lt; $-Z_{\alpha/2}$ atau jika $Z_{hit} &amp;lt; -Z_{\alpha}$ Bagaimana melakukan Uji Rata-rata 1 Populasi dengan nilai varians tidak diketahui?</description></item><item><title>under-coverage-bias</title><link>https://aradinka.github.io/under-coverage-bias/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/under-coverage-bias/</guid><description> It is the bias from sampling too few observations</description></item><item><title>underfitting</title><link>https://aradinka.github.io/underfitting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/underfitting/</guid><description>An underfitting model is the one that does not fit well with the training data, i.e. significantly deviated from the ground truth</description></item><item><title>underfitting-overfitting</title><link>https://aradinka.github.io/underfitting-overfitting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/underfitting-overfitting/</guid><description>When we say a model is underfitting or overfitting, it implies that the model does not generalized well to the unseen data.</description></item><item><title>upsampling and downsampling</title><link>https://aradinka.github.io/upsampling-downsampling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/upsampling-downsampling/</guid><description>Degree of imbalance:
Mid: 20-40% Moderate: 1-20% Extreme: 1% Up-sampling
Randomly duplicating observations from minority class Tools: sklearn.</description></item><item><title>variance</title><link>https://aradinka.github.io/variance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/variance/</guid><description> variance is the tendency to learn random things unrelated to the real signal</description></item><item><title>vim-bindings</title><link>https://aradinka.github.io/vim-bindings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/vim-bindings/</guid><description>move around: h, j, k, l
go to the start / end of a line: 0, $</description></item><item><title>vintage-analysis</title><link>https://aradinka.github.io/vintage-analysis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/vintage-analysis/</guid><description>Measures the performance of a portfolio in different periods of time after the loan was granted
Performance can be measured in the form of cumulative [[charge-off-rate]], proportion of cutomers 30/60/90 days past due (DPD), utilization ratio, average balance etc.</description></item><item><title>weight-of-evidence</title><link>https://aradinka.github.io/weight-of-evidence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/weight-of-evidence/</guid><description>Weight of Evidence Weight of Evidence(WoE):
$$wo{e_i} = \ln {{{P_{yi}}} \over {{P_{ni}}}} = \ln {{{y_i}/{y_s}} \over {{n_i}/{n_s}}}$$
$wo{e_i}$ is the I category&amp;rsquo;s WOE value.</description></item><item><title>weights in deep learning</title><link>https://aradinka.github.io/weights/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/weights/</guid><description>Weights are usually initialised randomly. The initialization takes a fair amount of repetitions to converge to the least loss and reach the ideal weight matrix.</description></item><item><title>What is l1 regularization?</title><link>https://aradinka.github.io/l1-regularization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/l1-regularization/</guid><description>The main objective of creating a model (training data) is making sure it fits the data properly and reduce the loss.</description></item><item><title>What is l2 regularization?</title><link>https://aradinka.github.io/l2-regularization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/l2-regularization/</guid><description>Overfitting happens when the model learns signal as well as noise in the training data and wouldn&amp;rsquo;t perform well on new/unseen data on which model wasn&amp;rsquo;t trained on.</description></item><item><title>What is linear regression?</title><link>https://aradinka.github.io/linear-regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/linear-regression/</guid><description>Linear Regressions Linear regressions tends to establish a relationship between a dependent variable Y and one or more independent variable X by finding the best fit of the straight line.</description></item><item><title>What is machine learning?</title><link>https://aradinka.github.io/machine-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/machine-learning/</guid><description>Machine learning is the scientific study of algorithms and statistical models that computer systems use to affectively perform a specific task without using explicit instruction, relyring on patterns and inference instead.</description></item><item><title>What is mean square error?</title><link>https://aradinka.github.io/mean-square-error/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/mean-square-error/</guid><description>The mean squared error tells you how close a regression line is to a set of points. It does this by taking the distance from the points to the regression line (these distance are the &amp;ldquo;errors&amp;rdquo;) and squaring them.</description></item><item><title>What is ordinary least square model?</title><link>https://aradinka.github.io/ordinary-least-square-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ordinary-least-square-model/</guid><description>OLS (Ordinary Least Square) is a stats model, which will help us in identifying the more significant features that can has an influence on the output.</description></item><item><title>What is R squared?</title><link>https://aradinka.github.io/r-squared/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/r-squared/</guid><description>R-squared is a statistical measure of how close the data are to the fitted regression line. It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression.</description></item><item><title>What is support vector regression?</title><link>https://aradinka.github.io/support-vector-regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/support-vector-regression/</guid><description>Why SVR (support vector regression)? What is the difference between SVR and a simple regression model?
The answer is, simple linear regression try to minimize the error rate.</description></item><item><title>What is the difference between AI, DS, ML and DL?</title><link>https://aradinka.github.io/difference-between-ai-ds-ml-dl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/difference-between-ai-ds-ml-dl/</guid><description>Artificial Intelligence AI is purely math and scientifc exercise, but when it became computational, it started to solve human problems formalized into [[a subset of computer science]].</description></item><item><title>What is the difference between supervised, unsupervised, and reinforcement learning?</title><link>https://aradinka.github.io/difference-between-supervised-unsupervised-reinforcement-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/difference-between-supervised-unsupervised-reinforcement-learning/</guid><description>Supervised Learning In a supervised learning model, the algorithm learns on a labeled dataset, to generate reasonable predictions for the response to new data.</description></item></channel></rss>