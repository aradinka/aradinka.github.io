<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Summary It&rsquo;s a tree-shaped supervised learning algorithm, works on if-then statement, that can be used in classification and regression problems. The input can be both continuous and categorical."><title>decision-tree</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://aradinka.github.io//icon.png><link href=https://aradinka.github.io/styles.cf285ee761306f0a5b31350a3b8e890f.min.css rel=stylesheet><link href=https://aradinka.github.io/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://aradinka.github.io/js/darkmode.edc10d5aea42c7df61e6a7cf92fc4f03.min.js></script>
<script src=https://aradinka.github.io/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://aradinka.github.io/js/popover.9b72b70bd35617d0635e9d15463662b2.min.js></script>
<script src=https://aradinka.github.io/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://aradinka.github.io/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://aradinka.github.io/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const BASE_URL="https://aradinka.github.io/",fetchData=Promise.all([fetch("https://aradinka.github.io/indices/linkIndex.78fd04624d2b2544ae32074f405bf875.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://aradinka.github.io/indices/contentIndex.1bacadc67ac3d6044126f522c5d4cdf1.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://aradinka.github.io",!0,!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://aradinka.github.io",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/aradinka.github.io\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XYFD95KB4J",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://aradinka.github.io/js/full-text-search.24827f874defbbc6d529926cbfcfb493.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://aradinka.github.io/>ðŸª´ Aradinka Digital Garden</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>decision-tree</h1><p class=meta>Last updated
Jan 1, 2023</p><ul class=tags><li><a href=https://aradinka.github.io/tags/all-post/>All post</a></li><li><a href=https://aradinka.github.io/tags/algorithm/>Algorithm</a></li></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#summary>Summary</a><ol><li><a href=#overfitting-and-instability-of-decision-trees>Overfitting and Instability of Decision Trees</a></li></ol></li><li><a href=#depth-of-the-tree>Depth of the tree</a></li><li><a href=#splitting-the-data>Splitting the Data</a></li><li><a href=#control-overfitting-in-decision-tree>Control overfitting in decision tree</a></li><li><a href=#algorithm>Algorithm</a><ol><li><a href=#id3-iterative-dichotomiser>ID3 (Iterative Dichotomiser)</a></li></ol></li><li><a href=#reference>Reference</a></li></ol></nav></details></aside><a href=#summary><h2 id=summary><span class=hanchor arialabel=Anchor># </span>Summary</h2></a><p>It&rsquo;s a tree-shaped supervised learning algorithm, works on if-then statement, that can be used in classification and regression problems. The input can be both continuous and categorical. Feature values are preferred to be categorical, if continuous they are discretized.</p><p>Advantages:</p><ul><li>can handle missing values</li><li>explainable and interpretable</li></ul><p>Disadvantages:</p><ul><li>prone to <a href=/overfitting rel=noopener class=internal-link data-src=/overfitting>overfitting</a></li><li>sensitive to <a class="internal-link broken">outlier</a></li></ul><p>Use Cases:</p><ul><li><a class="internal-link broken">customer-churn-prediction</a></li><li><a href=/credit-scoring rel=noopener class=internal-link data-src=/credit-scoring>credit-scoring</a></li><li><a class="internal-link broken">disease-prediction</a></li></ul><a href=#overfitting-and-instability-of-decision-trees><h3 id=overfitting-and-instability-of-decision-trees><span class=hanchor arialabel=Anchor># </span>Overfitting and Instability of Decision Trees</h3></a><p>Overfitting:</p><ul><li>Decision trees prone to <a href=/overfitting rel=noopener class=internal-link data-src=/overfitting>overfitting</a> the data. Since <strong>accuracy improves with each internal node</strong>, <strong>training will tend to grow a tree to its maximum</strong> to improve the performance metrics.</li><li>That deteriorates the treeâ€™s generalization capability and usefulness on unseen data since it will start modeling the noise</li></ul><p>Instability:</p><ul><li>We can limit the treeâ€™s depth beforehand, but thereâ€™s still the problem of instability</li><li>even <strong>small changes to the training data</strong>, such as excluding a few instances, <strong>can result in a completely different tree</strong></li></ul><a href=#depth-of-the-tree><h2 id=depth-of-the-tree><span class=hanchor arialabel=Anchor># </span>Depth of the tree</h2></a><p>When we divide the houses amongst many leaves, we also have fewer houses in each leaf. Leaves with very few houses will make predictions that are quite close to those homes&rsquo; actual values, but they may make very unreliable predictions for new data (because each prediction is based on only a few houses).</p><p>On the flip side, if we make our tree very shallow, it doesn&rsquo;t divide up the houses into very distinct groups.</p><p>At an extreme, if a tree divides houses into only 2 or 4, each group still has a wide variety of houses. Resulting predictions may be far off for most houses, even in the training data (and it will be bad in validation too for the same reason)</p><p>Â A deep tree with lots of leaves will overfit because each prediction is coming from historical data from only the few houses at its leaf. But a shallow tree with few leaves will perform poorly because it fails to capture as many distinctions in the raw data.</p><a href=#splitting-the-data><h2 id=splitting-the-data><span class=hanchor arialabel=Anchor># </span>Splitting the Data</h2></a><blockquote><p>When splitting, we choose to partition the data by the attribute that results in the <strong>smallest impurity</strong> of the new nodes</p></blockquote><a href=#control-overfitting-in-decision-tree><h2 id=control-overfitting-in-decision-tree><span class=hanchor arialabel=Anchor># </span>Control overfitting in decision tree</h2></a><p><em>max_leaf_nodes</em> argument provides a very sensible way to control overfitting vs underfitting. The more leaves we allow the model to make, the more we move from the underfitting area to the overfitting area.</p><a href=#algorithm><h2 id=algorithm><span class=hanchor arialabel=Anchor># </span>Algorithm</h2></a><blockquote><p>A decision tree uses different algorithms to decide whether to split a node into two or more sub-nodes. <strong>The algorithm chooses the partition maximizing the purity of the split (i.e., minimizing the <a href=/impurity rel=noopener class=internal-link data-src=/impurity>impurity</a>)</strong></p></blockquote><p>impurity is a measure of <strong>homogeneity</strong> of theÂ labelsÂ at the node at hand</p><a href=#id3-iterative-dichotomiser><h3 id=id3-iterative-dichotomiser><span class=hanchor arialabel=Anchor># </span>ID3 (Iterative Dichotomiser)</h3></a><ul><li>Uses <a href=/entropy rel=noopener class=internal-link data-src=/entropy>entropy</a> and <a class="internal-link broken">information-gain</a> as metrics to form a better decision tree</li><li>The attribute with the highest information gain is used as a root node, and a similar approach is followed after that</li><li>Entropy is the measure that characterizes the <a href=/impurity rel=noopener class=internal-link data-src=/impurity>impurity</a> of an arbitrary collection of examples</li><li>when entropy $H(S)=0$, the set is perfectly classified (all element in $S$ are of the same class)</li><li>when entropy $H(S)=1$, the class distribution is equal</li><li>entropy is calculated for each remaining attribute, the attribute with the smallest entropy is used to split the set $S$ on this iteration</li><li>the higher the entropy, the higher potential to improve the classification here</li></ul><p><img src=https://aradinka.github.io//entropy-1.png width=auto alt></p><a href=#reference><h2 id=reference><span class=hanchor arialabel=Anchor># </span>Reference</h2></a><ul><li><a href=https://www.baeldung.com/cs/decision-trees-vs-random-forests rel=noopener>https://www.baeldung.com/cs/decision-trees-vs-random-forests</a></li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/ data-ctx=decision-tree data-src=/ class=internal-link>Aradinka | Digital Garden</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://aradinka.github.io/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Aradinka Digital Garden using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2023</p><ul><li><a href=https://aradinka.github.io/>Home</a></li><li><a href=https://github.com/aradinka>Github</a></li></ul></footer></div></div></body></html>