<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>all-post on</title><link>https://aradinka.github.io/tags/all-post/</link><description>Recent content in all-post on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://aradinka.github.io/tags/all-post/index.xml" rel="self" type="application/rss+xml"/><item><title>batch-size</title><link>https://aradinka.github.io/batch-size/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/batch-size/</guid><description>Baca tentang [[batch-nomalization]]
Batch size salah satu yang bisa kita tuning. Tuning batch sizenya sampai kita mendapatkan performa yang maksimum</description></item><item><title>bias-vs-variance</title><link>https://aradinka.github.io/bias-vs-variance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/bias-vs-variance/</guid><description>It provides another perspective to look at the phenomenon of [[underfitting]] and [[overfitting]]</description></item><item><title>convolutional-neural-network</title><link>https://aradinka.github.io/convolutional-neural-network/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/convolutional-neural-network/</guid><description>Kenapa cnn bagus untuk dipakai di data image, text, audio dan video?
Mencerminkan spatial correlation between features Di data image: Pixel di titik i, j sangat berkaitan dengan i+1, j+1.</description></item><item><title>ds-ml-step</title><link>https://aradinka.github.io/ds-ml-step/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ds-ml-step/</guid><description>ML steps:
determine which type of ML problems we would like to solve gather data [[feature-engineering]] Reference</description></item><item><title>ds-skill</title><link>https://aradinka.github.io/ds-skill/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ds-skill/</guid><description> [[feature-engineering]] [[hyper-parameter-tuning]]</description></item><item><title>feature-engineering</title><link>https://aradinka.github.io/feature-engineering/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/feature-engineering/</guid><description>a group of activities that trasnform data into desired format
example:
splitting data into training and testing handle missing values encode categorical attributes the outermost interface that we interact with the model</description></item><item><title>General Architechture of Machine Learning</title><link>https://aradinka.github.io/general-architechture-of-machine-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/general-architechture-of-machine-learning/</guid><description>Business Understanding: Understand the give use case and also it&amp;rsquo;s good to know more about the domain for which the use cases are built.</description></item><item><title>hyper-parameter-tuning</title><link>https://aradinka.github.io/hyper-parameter-tuning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/hyper-parameter-tuning/</guid><description>The reason that it is highlighted as &amp;lsquo;hyper&amp;rsquo; is because the parameters that we tune are the outermost interface that we interact with the model, which would eventually have impacts on the underlying parameters of the model</description></item><item><title>machine-learning-algorithm</title><link>https://aradinka.github.io/machine-learning-algorithm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/machine-learning-algorithm/</guid><description>A machine learning algorithm is the process that uncovers the underlying relationship whith the data
The outcome of a machine learning algorithm is called [[machine-learning-model]], which can be considered as a function $F$, which outputs certain results, when given the input.</description></item><item><title>machine-learning-model</title><link>https://aradinka.github.io/machine-learning-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/machine-learning-model/</guid><description>Rather than a predifined and fixed function, a machine learning model is dedrived from historical data. Therefore, when fed with with different data, the output of [[machine-learning-algorithm]] changes, i.</description></item><item><title>overfitting</title><link>https://aradinka.github.io/overfitting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/overfitting/</guid><description>An overfitting model is the one that fits well with the training data, i.e. little or no error, however it does not generalized well to the unseen data</description></item><item><title>regularization</title><link>https://aradinka.github.io/regularization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/regularization/</guid><description>penalizing the model that is over-complicated so that the algorithm is steered to generate a less complicated model while fitting the data</description></item><item><title>semi-supervised-learning</title><link>https://aradinka.github.io/semi-supervised-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/semi-supervised-learning/</guid><description>The data set is massive but the labeled sample are few
Training strategy:
we train a model with the labeled data, then we apply the model to predict the unlabeled data first cluster the images into groups (unsupervised learning), and then apply the supervised learning algorithm on each of the groups individually Reference</description></item><item><title>supervised-learning</title><link>https://aradinka.github.io/supervised-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/supervised-learning/</guid><description>An important measurement for supervised learning algorithms, is the generalization, which measures how well that a model derived from the training data can predict the desired attribute of the unseen data.</description></item><item><title>Tags System</title><link>https://aradinka.github.io/tags-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/tags-system/</guid><description>PARA Methods P.A.R.A. stands for Projects — Areas — Resources — Archives, the four top-level categories that encompass every type of information you might encounter in your work and life.</description></item><item><title>underfitting</title><link>https://aradinka.github.io/underfitting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/underfitting/</guid><description>An underfitting model is the one that does not fit well with the training data, i.e. significantly deviated from the ground truth</description></item><item><title>underfitting-overfitting</title><link>https://aradinka.github.io/underfitting-overfitting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/underfitting-overfitting/</guid><description>When we say a model is underfitting or overfitting, it implies that the model does not generalized well to the unseen data.</description></item><item><title>What is l1 regularization?</title><link>https://aradinka.github.io/l1-regularization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/l1-regularization/</guid><description>The main objective of creating a model (training data) is making sure it fits the data properly and reduce the loss.</description></item><item><title>What is l2 regularization?</title><link>https://aradinka.github.io/l2-regularization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/l2-regularization/</guid><description>Overfitting happens when the model learns signal as well as noise in the training data and wouldn&amp;rsquo;t perform well on new/unseen data on which model wasn&amp;rsquo;t trained on.</description></item><item><title>What is linear regression?</title><link>https://aradinka.github.io/linear-regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/linear-regression/</guid><description>Linear Regressions Linear regressions tends to establish a relationship between a dependent variable Y and one or more independent variable X by finding the best fit of the straight line.</description></item><item><title>What is machine learning?</title><link>https://aradinka.github.io/machine-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/machine-learning/</guid><description>Machine learning is the scientific study of algorithms and statistical models that computer systems use to affectively perform a specific task without using explicit instruction, relyring on patterns and inference instead.</description></item><item><title>What is mean square error?</title><link>https://aradinka.github.io/mean-square-error/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/mean-square-error/</guid><description>The mean squared error tells you how close a regression line is to a set of points. It does this by taking the distance from the points to the regression line (these distance are the &amp;ldquo;errors&amp;rdquo;) and squaring them.</description></item><item><title>What is ordinary least square model?</title><link>https://aradinka.github.io/ordinary-least-square-model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/ordinary-least-square-model/</guid><description>OLS (Ordinary Least Square) is a stats model, which will help us in identifying the more significant features that can has an influence on the output.</description></item><item><title>What is R squared?</title><link>https://aradinka.github.io/r-squared/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/r-squared/</guid><description>R-squared is a statistical measure of how close the data are to the fitted regression line. It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression.</description></item><item><title>What is support vector regression?</title><link>https://aradinka.github.io/support-vector-regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/support-vector-regression/</guid><description>Why SVR (support vector regression)? What is the difference between SVR and a simple regression model?
The answer is, simple linear regression try to minimize the error rate.</description></item><item><title>What is the difference between AI, DS, ML and DL?</title><link>https://aradinka.github.io/difference-between-ai-ds-ml-dl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/difference-between-ai-ds-ml-dl/</guid><description>Artificial Intelligence AI is purely math and scientifc exercise, but when it became computational, it started to solve human problems formalized into [[a subset of computer science]].</description></item><item><title>What is the difference between supervised, unsupervised, and reinforcement learning?</title><link>https://aradinka.github.io/difference-between-supervised-unsupervised-reinforcement-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://aradinka.github.io/difference-between-supervised-unsupervised-reinforcement-learning/</guid><description>Supervised Learning In a supervised learning model, the algorithm learns on a labeled dataset, to generate reasonable predictions for the response to new data.</description></item></channel></rss>